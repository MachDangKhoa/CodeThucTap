import base64
import os
import time
import uuid
import json
from skimage.transform import resize
import requests
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import undetected_chromedriver as uc
import cv2
import numpy as np
from skimage.metrics import structural_similarity as ssim
from selenium.webdriver.common.action_chains import ActionChains
from extract_dino_features import extract_dino_features
from detect_image import crop_painting
import google.generativeai as genai
import re
from underthesea import ner

# C·∫•u h√¨nh API Google Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "AIzaSyA-Lymc-kEm_p00YMcQEbAlvgO79ZO-fgQ")
genai.configure(api_key=GOOGLE_API_KEY)

SIM_THRESHOLD = 0.55
output_image = "D:/LuanVanTotNghiep/NhanDienThongTinTranh/demo.jpg"
EXCLUDED_DOMAINS = [
    "google.com", "accounts.google.com", "policies.google.com", "support.google.com",
    "myactivity.google.com", "www.google.com.vn", "www.google.com"
]


def is_valid_article_url(img_url):
    if not img_url:
        return False
        # Lo·∫°i b·ªè ·∫£nh base64
    if img_url.startswith("data:image"):
        return False
        # Lo·∫°i b·ªè ·∫£nh c√≥ k√≠ch th∆∞·ªõc nh·ªè (logo, icon)
    if "logo" in img_url.lower() or "icon" in img_url.lower():
        return False
    return True


def save_temp_image(image):
    """L∆∞u m·∫£ng ·∫£nh NumPy v√†o th∆∞ m·ª•c ch·ªâ ƒë·ªãnh v√† tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n."""
    save_dir = "D:/LuanVanTotNghiep/NhanDienThongTinTranh/"
    os.makedirs(save_dir, exist_ok=True)  # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i

    filename = f"temp_{uuid.uuid4().hex}.jpg"  # T·∫°o t√™n file ng·∫´u nhi√™n
    temp_file_path = os.path.join(save_dir, filename)

    cv2.imwrite(temp_file_path, image)  # L∆∞u ·∫£nh v√†o file
    return temp_file_path


def preprocess_image(image, mode='gray'):
    """
    H√†m ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒë·ªÉ √°p d·ª•ng c√°c ph∆∞∆°ng ph√°p l·ªçc.
    - mode='gray' s·∫Ω chuy·ªÉn ·∫£nh sang grayscale
    - mode='rgb' s·∫Ω gi·ªØ ·∫£nh nguy√™n tr·∫°ng n·∫øu l√† ·∫£nh RGB
    """
    if mode == 'gray':
        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Chuy·ªÉn sang grayscale
    elif mode == 'rgb' and len(image.shape) == 2:  # Chuy·ªÉn t·ª´ grayscale sang RGB n·∫øu c·∫ßn
        return cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
    elif mode == 'hsv':
        return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    return image


def histogram_matching(image1, image2):
    """
    So s√°nh histogram c·ªßa ·∫£nh theo kh√¥ng gian m√†u HSV v√† grayscale.
    """
    similarity_hsv = 0

    # Chuy·ªÉn ·∫£nh sang HSV n·∫øu ch∆∞a ·ªü HSV
    if len(image1.shape) == 3:  # Ki·ªÉm tra xem c√≥ ph·∫£i ·∫£nh m√†u kh√¥ng
        image1_hsv = cv2.cvtColor(image1, cv2.COLOR_BGR2HSV)
        image2_hsv = cv2.cvtColor(image2, cv2.COLOR_BGR2HSV)
    else:
        raise ValueError("·∫¢nh ƒë·∫ßu v√†o ph·∫£i c√≥ 3 k√™nh m√†u BGR!")

    # So s√°nh histogram trong kh√¥ng gian HSV
    for i in range(3):  # H, S, V
        hist1 = cv2.calcHist([image1_hsv], [i], None, [256], [0, 256])
        hist2 = cv2.calcHist([image2_hsv], [i], None, [256], [0, 256])

        hist1 = cv2.normalize(hist1, hist1).flatten()
        hist2 = cv2.normalize(hist2, hist2).flatten()

        similarity_hsv += cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)

    similarity_hsv /= 3  # L·∫•y trung b√¨nh tr√™n 3 k√™nh H, S, V

    # So s√°nh histogram trong kh√¥ng gian ·∫£nh x√°m
    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

    hist1_gray = cv2.calcHist([image1_gray], [0], None, [256], [0, 256])
    hist2_gray = cv2.calcHist([image2_gray], [0], None, [256], [0, 256])

    hist1_gray = cv2.normalize(hist1_gray, hist1_gray).flatten()
    hist2_gray = cv2.normalize(hist2_gray, hist2_gray).flatten()

    similarity_gray = cv2.compareHist(hist1_gray, hist2_gray, cv2.HISTCMP_CORREL)

    # Tr·ªçng s·ªë cho m·ªói lo·∫°i (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)
    alpha = 0.7  # HSV quan tr·ªçng h∆°n m√†u x√°m
    beta = 0.3  # ·∫¢nh x√°m c√≥ tr·ªçng s·ªë th·∫•p h∆°n

    total_similarity = alpha * similarity_hsv + beta * similarity_gray

    return total_similarity


def ssim_compare(image1, image2):
    # Resize image2 theo k√≠ch th∆∞·ªõc c·ªßa image1
    image2_resized = resize(image2, image1.shape, anti_aliasing=True)

    # X√°c ƒë·ªãnh gi√° tr·ªã win_size ph√π h·ª£p
    min_dim = min(image1.shape[0], image1.shape[1])  # Chi·ªÅu nh·ªè nh·∫•t c·ªßa ·∫£nh
    win_size = min(7, min_dim)  # Gi·ªØ win_size <= chi·ªÅu nh·ªè nh·∫•t c·ªßa ·∫£nh

    # Chuy·ªÉn v·ªÅ float64 n·∫øu c·∫ßn
    image1 = image1.astype(np.float64)
    image2_resized = image2_resized.astype(np.float64)

    # X√°c ƒë·ªãnh data_range
    data_range = image1.max() - image1.min()

    return ssim(image1, image2_resized, channel_axis=-1, win_size=win_size, data_range=data_range)


def sift_match(image1, image2):
    sift = cv2.SIFT_create()
    kp1, des1 = sift.detectAndCompute(image1, None)
    kp2, des2 = sift.detectAndCompute(image2, None)

    if des1 is None or des2 is None:
        return 0

    bf = cv2.BFMatcher()
    matches = bf.knnMatch(des1, des2, k=2)
    good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]
    return len(good_matches) / min(len(kp1), len(kp2))


def dino_similarity(image1, image2):
    # G·ªçi h√†m DINOv2 ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng ·∫£nh (c·∫ßn c√≥ m√¥ h√¨nh DINOv2 c√†i s·∫µn)
    features1 = extract_dino_features(image1)
    features2 = extract_dino_features(image2)
    if features1 is None or features2 is None:
        print("‚ùå DINO kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng.")
    else:
        cosine_sim = np.dot(features1, features2) / (np.linalg.norm(features1) * np.linalg.norm(features2))
        print(f"üß† DINO Cosine Similarity: {cosine_sim}")
        return cosine_sim


def process_image_for_search(image_path):
    try:
        crop_painting(image_path, output_image)
        image = cv2.imread(output_image)  # ƒê·ªçc ·∫£nh m√†u
        image_rgb = preprocess_image(image, mode='rgb')  # Gi·ªØ nguy√™n ·∫£nh RGB
        image_gray = preprocess_image(image, mode='gray')  # Chuy·ªÉn ·∫£nh sang grayscale
        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)  # Chuy·ªÉn ·∫£nh sang HSV

        print(f"Image loaded: {image.shape}")

        # Ti·∫øn h√†nh l·ªçc ·∫£nh
        best_image = None
        images_to_process = "D:/LuanVanTotNghiep/NhanDienThongTinTranh/temp_images"
        image_files = [os.path.join(images_to_process, f) for f in os.listdir(images_to_process)]

        images = []
        for img_path in image_files:
            img = cv2.imread(img_path)
            if img is not None:
                images.append(img)
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}")

        # 1. L·ªçc Histogram k·∫øt h·ª£p HSV + Grayscale
        for img in images:
            if len(img.shape) == 2:
                img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
            img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            hist_score = histogram_matching(image_hsv, img_hsv)
            print(f"üìä Histogram similarity: {hist_score}")

            if hist_score > SIM_THRESHOLD:
                # 2. L·ªçc SSIM (tr√™n ·∫£nh RGB)
                ssim_score = ssim_compare(image_rgb, img)
                print(f"üìà SSIM Score: {ssim_score}")

                if ssim_score >= SIM_THRESHOLD:
                    best_image = img
                    break

        # N·∫øu kh√¥ng c√≥ ·∫£nh n√†o t·ªët, th·ª±c hi·ªán b∆∞·ªõc SIFT tr√™n ·∫£nh Grayscale
        sift_candidates = []

        if best_image is None:
            for img in images:
                img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Chuy·ªÉn v·ªÅ grayscale n·∫øu c·∫ßn
                sift_score = sift_match(image_gray, img_gray)
                print(f"üîç SIFT Score: {sift_score}")

                if sift_score > SIM_THRESHOLD:
                    sift_candidates.append((img, sift_score))

        # N·∫øu ch·ªâ c√≥ ƒë√∫ng 1 ·∫£nh ƒë·∫°t ng∆∞·ª°ng SIFT, ch·ªçn ngay
        if len(sift_candidates) == 1:
            best_image = sift_candidates[0][0]
        elif len(sift_candidates) > 1:
            images = [img for img, _ in sift_candidates]

        # N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c ·∫£nh t·ªët, d√πng DINOv2 tr√™n ·∫£nh RGB
        if best_image is None:
            max_dino_score = -1
            for img in images:
                dino_score = dino_similarity(image, img)
                if dino_score > max_dino_score:
                    max_dino_score = dino_score
                    best_image = img

        if best_image is None:
            print("Kh√¥ng t√¨m ƒë∆∞·ª£c ·∫£nh ph√π h·ª£p.")
            return None

        temp_image_path = save_temp_image(best_image)
        print(temp_image_path)

        # T√¨m ki·∫øm l·∫°i tr√™n Google v√† l·∫•y n·ªôi dung b√†i b√°o
        result = search_google_and_extract_info(temp_image_path)
        return result
    finally:
        if os.path.exists(temp_image_path):
            os.remove(temp_image_path)
            print(f"ƒê√£ x√≥a file: {temp_image_path}")
        else:
            print(f"File {temp_image_path} kh√¥ng t·ªìn t·∫°i.")


def extract_info_from_article(page_url):
    try:
        response = requests.get(page_url, timeout=10)
        if response.status_code != 200:
            return {"description": "Kh√¥ng r√µ", "source_page": page_url}

        soup = BeautifulSoup(response.text, "html.parser")
        paragraphs = soup.find_all("p")
        description = " ".join([p.text.strip() for p in paragraphs]) if paragraphs else "Kh√¥ng r√µ"

        return {"description": description, "source_page": page_url}
    except Exception as e:
        return {"description": f"L·ªói ph√¢n t√≠ch b√†i b√°o: {e}", "source_page": page_url}


def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def extract_info_from_gemini(image_path, articles):
    try:
        # Gh√©p n·ªëi t·∫•t c·∫£ c√°c m√¥ t·∫£ t·ª´ b√†i vi·∫øt
        description_text = " ".join([article["description"] for article in articles])
        image_data = encode_image(image_path)  # H√†m n√†y c·∫ßn ph·∫£i ƒë·ªãnh nghƒ©a ƒë·ªÉ m√£ h√≥a ·∫£nh

        # T·∫°o prompt cho Gemini
        prompt = (
            f"Ph√¢n t√≠ch b·ª©c tranh t·ª´ h√¨nh ·∫£nh v√† th√¥ng tin b√†i vi·∫øt d∆∞·ªõi ƒë√¢y: {description_text}. "
            "Tr·∫£ l·ªùi chi ti·∫øt v√† c·ª• th·ªÉ v·ªÅ c√°c th√¥ng tin sau: "
            "- T√™n b·ª©c tranh. "
            "- T√™n ngh·ªá sƒ© (n·∫øu c√≥). "
            "- Phong c√°ch v√† c√°c ƒë·∫∑c ƒëi·ªÉm ngh·ªá thu·∫≠t n·ªïi b·∫≠t c·ªßa t√°c ph·∫©m. "
            "- Th·ªÉ lo·∫°i c·ªßa b·ª©c tranh (v√≠ d·ª•: tranh ng·ª±a, phong c·∫£nh, v.v.). "
            "- NƒÉm s√°ng t√°c (n·∫øu c√≥ th√¥ng tin). "
            "- M√¥ t·∫£ chi ti·∫øt v·ªÅ b·ª©c tranh, c√°c ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t nh∆∞ m√†u s·∫Øc, h√¨nh d√°ng, v√† b·ªë c·ª•c. "
            "- C√°c y·∫øu t·ªë ƒë·∫∑c bi·ªát ho·∫∑c th√¥ng tin b·ªï sung (v√≠ d·ª•: k√Ω hi·ªáu, ch·ªØ k√Ω, v.v.). "
            "Tr·∫£ k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng JSON n·∫øu c√≥ th·ªÉ. N·∫øu kh√¥ng, tr·∫£ l·ªùi d∆∞·ªõi d·∫°ng vƒÉn b·∫£n m√¥ t·∫£ chi ti·∫øt."
        )

        # Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
        model = genai.GenerativeModel("gemini-1.5-pro-latest")
        response = model.generate_content(
            contents=[{"mime_type": "image/jpeg", "data": image_data}, prompt]
        )

        result = response.text if hasattr(response, 'text') else response.content if hasattr(response,
                                                                                             'content') else ""

        # In k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ Gemini ƒë·ªÉ debug
        print("Result from Gemini:", result)

        # Ki·ªÉm tra xem response c√≥ h·ª£p l·ªá kh√¥ng
        if not result:
            return {"error": "Kh√¥ng c√≥ k·∫øt qu·∫£ tr·∫£ v·ªÅ t·ª´ Gemini."}

        # ƒê·ªãnh nghƒ©a c√°c t·ª´ kh√≥a chu·∫©n m√† b·∫°n mu·ªën tr√≠ch xu·∫•t
        predefined_keywords = {
            "title": ["title", "painting_title", "name_of_painting", "t√™n_b·ª©c_tranh"],  # Th√™m t·ª´ kh√≥a cho t√™n b·ª©c tranh
            "artist": ["artist", "name", "author", "t√™n_ngh·ªá_sƒ©"],
            "style": ["style", "artistic_style", "genre_style", "phong_c√°ch"],
            "genre": ["genre", "type", "category", "th·ªÉ_lo·∫°i"],
            "year": ["year", "year_of_creation", "creation_year", "nƒÉm_s√°ng_t√°c"],
            "description": ["description", "details", "painting_description", "m√¥_t·∫£"],
            "artistic_features": ["artistic_features", "special_features", "painting_features", "characteristics",
                                  "ƒë·∫∑c_ƒëi·ªÉm_ngh·ªá_thu·∫≠t"],
            "additional_information": ["additional_information", "extra_info", "additional_details",
                                       "additional_info", "y·∫øu_t·ªë_ƒë·∫∑c_bi·ªát"]
        }

        # C·ªë g·∫Øng ph√¢n t√≠ch k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng JSON
        try:
            # Ki·ªÉm tra n·∫øu k·∫øt qu·∫£ l√† m·ªôt chu·ªói JSON h·ª£p l·ªá
            result_json = json.loads(result)

            # Kh·ªõp c√°c t·ª´ kh√≥a v·ªõi c√°c kh√≥a trong JSON
            extracted_info = {}
            for key, possible_keys in predefined_keywords.items():
                for possible_key in possible_keys:
                    if possible_key in result_json:
                        extracted_info[key] = result_json[possible_key]
                        break
                # N·∫øu kh√¥ng t√¨m th·∫•y b·∫•t k·ª≥ kh√≥a n√†o, g√°n gi√° tr·ªã m·∫∑c ƒë·ªãnh
                if key not in extracted_info:
                    extracted_info[key] = "Kh√¥ng c√≥ th√¥ng tin"

            return extracted_info  # Tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON n·∫øu ph√¢n t√≠ch th√†nh c√¥ng
        except json.JSONDecodeError:
            # N·∫øu kh√¥ng ph·∫£i JSON, s·ª≠ d·ª•ng regex ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin c·∫ßn thi·∫øt
            extracted_info = {
                "title": "Kh√¥ng c√≥ th√¥ng tin",  # Th√™m gi√° tr·ªã m·∫∑c ƒë·ªãnh cho t√™n b·ª©c tranh
                "artist": "Kh√¥ng c√≥ th√¥ng tin",
                "style": "Kh√¥ng c√≥ th√¥ng tin",
                "genre": "Kh√¥ng c√≥ th√¥ng tin",
                "year": "Kh√¥ng c√≥ th√¥ng tin",
                "description": "Kh√¥ng c√≥ th√¥ng tin",
                "artistic_features": "Kh√¥ng c√≥ th√¥ng tin",
                "additional_info": "Kh√¥ng c√≥ th√¥ng tin"
            }

            # S·ª≠ d·ª•ng regex ƒë·ªÉ tr√≠ch xu·∫•t c√°c th√¥ng tin kh√°c
            extracted_info["title"] = re.search(r"\"title\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"painting_title\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"name_of_painting\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"t√™n_b·ª©c_tranh\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["artist"] = re.search(r"\"artist\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"name\"\s*:\s*\"([^\"]+)\"", result) or re.search(r"\"author\"\s*:\s*\"([^\"]+)\"",
                                                                     result) or re.search(
                r"\"t√™n_ngh·ªá_sƒ©\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["style"] = re.search(r"\"style\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"artistic_style\"\s*:\s*\"([^\"]+)\"", result) or re.search(r"\"phong_c√°ch\"\s*:\s*\"([^\"]+)\"",
                                                                               result)
            extracted_info["genre"] = re.search(r"\"genre\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"type\"\s*:\s*\"([^\"]+)\"", result) or re.search(r"\"th·ªÉ_lo·∫°i\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["year"] = re.search(r"\"year_of_creation\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"year\"\s*:\s*\"([^\"]+)\"", result) or re.search(r"\"creation_year\"\s*:\s*\"([^\"]+)\"",
                                                                     result) or re.search(
                r"\"nƒÉm_s√°ng_t√°c\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["description"] = re.search(r"\"description\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"m√¥_t·∫£\"\s*:\s*\"([^\"]+)\"", result) or re.search(r"\"m√¥_t·∫£_chi_ti·∫øt\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["artistic_features"] = re.search(r"\"artistic_features\"\s*:\s*\[([^\]]+)\]",
                                                            result) or re.search(
                r"\"characteristics\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"ƒë·∫∑c_ƒëi·ªÉm_ngh·ªá_thu·∫≠t\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"ƒë·∫∑c_ƒëi·ªÉm_ngh·ªá_thu·∫≠t_n·ªïi_b·∫≠t\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"artistic_features\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"characteristics\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"ƒë·∫∑c_ƒëi·ªÉm_ngh·ªá_thu·∫≠t\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"ƒë·∫∑c_ƒëi·ªÉm_ngh·ªá_thu·∫≠t_n·ªïi_b·∫≠t\"\s*:\s*\"([^\"]+)\"", result)
            extracted_info["additional_info"] = re.search(r"\"additional_information\"\s*:\s*\[([^\]]+)\]",
                                                          result) or re.search(
                r"\"additional_info\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"y·∫øu_t·ªë_ƒë·∫∑c_bi·ªát\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"y·∫øu_t·ªë_ƒë·∫∑c_bi·ªát_ho·∫∑c_th√¥ng_tin_b·ªï_sung\"\s*:\s*\[([^\]]+)\]", result) or re.search(
                r"\"additional_information\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"additional_info\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"y·∫øu_t·ªë_ƒë·∫∑c_bi·ªát\"\s*:\s*\"([^\"]+)\"", result) or re.search(
                r"\"y·∫øu_t·ªë_ƒë·∫∑c_bi·ªát_ho·∫∑c_th√¥ng_tin_b·ªï_sung\"\s*:\s*\"([^\"]+)\"", result)

            # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ regex th√†nh gi√° tr·ªã th·ª±c t·∫ø
            extracted_info = {
                k: v.group(1).strip() if v else "Kh√¥ng c√≥ th√¥ng tin" for k, v in extracted_info.items()
            }

            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng vƒÉn b·∫£n m√¥ t·∫£ chi ti·∫øt
            detailed_description = (
                f"Th√¥ng tin v·ªÅ b·ª©c tranh:\n"
                f"1. T√™n b·ª©c tranh: {extracted_info['title']}\n"  # Th√™m t√™n b·ª©c tranh
                f"2. T√™n ngh·ªá sƒ©: {extracted_info['artist']}\n"
                f"3. Phong c√°ch v√† ƒë·∫∑c ƒëi·ªÉm ngh·ªá thu·∫≠t: {extracted_info['style']}\n"
                f"4. Th·ªÉ lo·∫°i: {extracted_info['genre']}\n"
                f"5. NƒÉm s√°ng t√°c: {extracted_info['year']}\n"
                f"6. M√¥ t·∫£: {extracted_info['description']}\n"
                f"7. C√°c ƒë·∫∑c ƒëi·ªÉm ngh·ªá thu·∫≠t n·ªïi b·∫≠t: {extracted_info['artistic_features']}\n"
                f"8. Th√¥ng tin b·ªï sung: {extracted_info['additional_info']}\n"
            )

            # Ki·ªÉm tra k·∫øt qu·∫£ cu·ªëi c√πng
            if all(value == "Kh√¥ng c√≥ th√¥ng tin" for value in extracted_info.values()):
                # N·∫øu t·∫•t c·∫£ c√°c tr∆∞·ªùng kh√¥ng c√≥ th√¥ng tin, tr·∫£ v·ªÅ vƒÉn b·∫£n m√¥ t·∫£ chi ti·∫øt
                return detailed_description
            else:
                # N·∫øu c√≥ b·∫•t k·ª≥ th√¥ng tin n√†o h·ª£p l·ªá, tr·∫£ v·ªÅ th√¥ng tin ƒë√£ tr√≠ch xu·∫•t
                return extracted_info

    except Exception as e:
        return {"error": f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin t·ª´ Gemini: {str(e)}"}


def search_google_and_extract_info(image_path):
    print("üîç ƒêang t√¨m ki·∫øm b√†i b√°o t·ª´ Google Image...")

    chrome_options = uc.ChromeOptions()
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-popup-blocking")
    chrome_options.add_argument("--disable-notifications")
    chrome_options.add_argument("--disable-infobars")
    chrome_options.add_argument("--disable-backgrounding-occluded-windows")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    driver = uc.Chrome(options=chrome_options)
    driver.execute_script("""
        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        Object.defineProperty(navigator, 'languages', {get: () => ['en-US', 'en']});
        Object.defineProperty(navigator, 'platform', {get: () => 'Win32'});""")

    try:
        driver.get("https://www.google.com/?hl=vi")
        driver.minimize_window()
        time.sleep(2)

        # Click v√†o n√∫t t√¨m ki·∫øm b·∫±ng h√¨nh ·∫£nh
        camera_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.XPATH, '//div[@aria-label="T√¨m ki·∫øm b·∫±ng h√¨nh ·∫£nh"]'))
        )
        camera_button.click()
        time.sleep(1)

        # Upload ·∫£nh ƒë·ªÉ t√¨m ki·∫øm
        file_input = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.XPATH, '//input[@type="file"]'))
        )
        abs_path = os.path.abspath(image_path)
        file_input.send_keys(abs_path)
        time.sleep(5)

        # Chuy·ªÉn sang tab "K·∫øt qu·∫£ kh·ªõp ch√≠nh x√°c"
        try:
            about_tab = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.XPATH, '//div[contains(text(), "K·∫øt qu·∫£ kh·ªõp ch√≠nh x√°c")]')))
            about_tab.click()
            time.sleep(1)

            article_links = driver.find_elements(By.XPATH, '//div[@id="search"]//a[contains(@href, "http")]')
            matched_articles = []

            for link in article_links:
                url = link.get_attribute("href")
                if not url or not is_valid_article_url(url):
                    continue

                article_info = extract_info_from_article(url)
                matched_articles.append(article_info)
                if len(matched_articles) >= 5:
                    break

            gemini_info = extract_info_from_gemini(image_path, matched_articles) if matched_articles else {}

            if matched_articles:
                result = {
                    "source": "Google Image",
                    "gemini_info": gemini_info
                }
                driver.quit()
                return result
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")

        try:
            img_tab = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, '//div[contains(text(), "H√¨nh ·∫£nh tr√πng kh·ªõp")]')))
            img_tab.click()
            time.sleep(2)

            images = driver.find_elements(By.XPATH, '//div[contains(@class, "gdOPf")]//img')
            if not images:
                print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh n√†o.")
                driver.quit()
                return {"error": "Kh√¥ng t√¨m th·∫•y ·∫£nh ph√π h·ª£p."}

            images_to_download = images[:10]
            os.makedirs("temp_images", exist_ok=True)
            action = ActionChains(driver)

            for idx, img in enumerate(images_to_download):
                try:
                    action.move_to_element(img).click().perform()
                    time.sleep(2)
                    large_images = driver.find_elements(By.XPATH, '//div[contains(@class, "p7sI2 PUxBg")]//img')
                    img_url = next((img.get_attribute("src") for img in large_images if img.get_attribute("src")), None)
                    if img_url:
                        with open(f"temp_images/image_{idx + 1}.jpg", "wb") as f:
                            f.write(requests.get(img_url).content)
                        print(f"‚úÖ ƒê√£ t·∫£i ·∫£nh {idx + 1}: {img_url}")
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi t·∫£i ·∫£nh {idx + 1}: {e}")

            driver.quit()

        except Exception as e:
            print(f"‚ùå L·ªói khi chuy·ªÉn tab h√¨nh ·∫£nh tr√πng kh·ªõp: {e}")
            driver.quit()
            return {"error": "Kh√¥ng th·ªÉ chuy·ªÉn tab h√¨nh ·∫£nh tr√πng kh·ªõp."}

    except Exception as ex:
        driver.quit()
        return {"error": f"L·ªói khi t√¨m ki·∫øm: {ex}"}

